# -*- coding: utf-8 -*-
"""Food-5K-test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q40ob5O470zuAekTnuodvuHsTwvHIgwP
"""

from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import os
from keras.applications.inception_v3 import InceptionV3, preprocess_input

from google.colab import drive
drive.mount('/content/drive')

model = load_model('/content/drive/My Drive/colab/Food-5K/food-5k_new_model.h5')

train_data_dir = '/content/drive/My Drive/colab/Food-5K/dataset/train'
test_data_dir = '/content/drive/My Drive/colab/Food-5K/dataset/test'

# dimensions of our images.
#Inception input size
img_width, img_height = 224, 224
batch_size = 24
image_size = (224, 224)

# we need to recompile the model for these modifications to take effect
# we use SGD with a low learning rate
from keras.optimizers import SGD
model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')

# get all the train labels
#train_labels = os.listdir(train_data_dir)
train_labels = ['non-food', 'food']

# get all the test images paths
test_images = os.listdir(test_data_dir)
corr = 0
i = 0

len(test_images)

test_data = []
test_labels = []
y_pred_nm = []
# loop through each image in the test data
for image_path in test_images:
    path 		= test_data_dir + "/" + image_path
    img 		= image.load_img(path, target_size=image_size)
    x 			= image.img_to_array(img)
    x 			= np.expand_dims(x, axis=0)
    x /= 255. 
    test_data.append(x)
    Y_pred = model.predict(x, verbose=1)
    y_pred = np.argmax(Y_pred, axis=1)
    y_pred_nm.append(y_pred[0])
    print(y_pred[0])
    y = int(image_path.split("_")[0])
    if(y == y_pred[0]):
        corr = corr + 1
    test_labels.append(y)
    print ("Actual image:   " + train_labels[y])
    print (image_path)
    print ("I think it is a " + train_labels[y_pred[0]])
    
len(test_data)

acc = (corr / float(len(test_images))) * 100
print("Accuracy: " + str(acc))
#Accuracy: 96.00 (224, 224)
#Accuracy: 50.00 (299, 299)
#Accuracy: 95.39999999999999 (reorder)
#Accuracy: 95.7  (correct number of train samples)

from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score
print('\n Report: ')
print('\n Accuracy:', accuracy_score(test_labels, y_pred_nm))
print('\n F1 score:', f1_score(test_labels, y_pred_nm))
print('\n Recall:', recall_score(test_labels, y_pred_nm))
print('\n Precision:', precision_score(test_labels, y_pred_nm))
print('\n clasification report:\n', classification_report(test_labels,y_pred_nm))
print('\n confussion matrix:\n',confusion_matrix(test_labels, y_pred_nm))

model.summary()